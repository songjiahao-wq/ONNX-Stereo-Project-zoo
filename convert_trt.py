# -*- coding: utf-8 -*-
# @Time    : 2025/3/20 15:47
# @Author  : sjh
# @File    : convert.py
# @Comment : Convert ONNX to TensorRT engine (FP16/FP32)

import tensorrt as trt
import os
from packaging import version
trt_version = trt.__version__
compare_version = version.parse("8.6.1")

# æ¯”è¾ƒç‰ˆæœ¬
if version.parse(trt_version) > compare_version:
    trt_version8_bool = False
    print(f"âœ… TensorRT ç‰ˆæœ¬ {trt_version} å¤§äºæˆ–ç­‰äº {compare_version}")
else:
    trt_version8_bool = True
    print(f"âŒ TensorRT ç‰ˆæœ¬ {trt_version} å°äº {compare_version}")

def convert_onnx_to_trt(onnx_path, fp16=True):
    """
    å°† ONNX è½¬æ¢ä¸º TensorRT Engine
    :param onnx_path: ONNX æ–‡ä»¶è·¯å¾„
    :param fp16: æ˜¯å¦å¼€å¯ FP16ï¼ˆé»˜è®¤å¼€å¯ï¼‰
    """
    # TensorRT æ—¥å¿—
    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)

    # åˆ›å»º Builder å’Œ Network
    builder = trt.Builder(TRT_LOGGER)
    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
    parser = trt.OnnxParser(network, TRT_LOGGER)

    # è¯»å– ONNX
    with open(onnx_path, "rb") as f:
        if not parser.parse(f.read()):
            print(f"âŒ è§£æ {onnx_path} å¤±è´¥ï¼é”™è¯¯ä¿¡æ¯å¦‚ä¸‹ï¼š")
            for i in range(parser.num_errors):
                print(parser.get_error(i))
            return

    # åˆ›å»º Builder é…ç½®
    config = builder.create_builder_config()

    # æ˜¯å¦å¼€å¯ FP16
    if fp16 and builder.platform_has_fast_fp16:
        print("âœ… å¼€å¯ FP16 æ¨¡å¼")
        config.set_flag(trt.BuilderFlag.FP16)
    else:
        print("âš ï¸ è®¾å¤‡ä¸æ”¯æŒ FP16ï¼Œä½¿ç”¨ FP32")

    # åˆ›å»ºåŠ¨æ€è¾“å…¥ Profile
    profile = builder.create_optimization_profile()
    min_shape = (1, 3, 392, 528)  # æœ€å°è¾“å…¥
    opt_shape = (1, 3, 392, 528)  # æœ€ä½³è¾“å…¥
    max_shape = (1, 3, 392, 528)  # æœ€å¤§è¾“å…¥

    profile.set_shape("left", min_shape, opt_shape, max_shape)
    profile.set_shape("right", min_shape, opt_shape, max_shape)
    config.add_optimization_profile(profile)

    # ç”Ÿæˆ Engine
    if trt_version8_bool:
        engine = builder.build_engine(network, config)
    else:
        engine = builder.build_serialized_network(network, config)
    if engine is None:
        print(f"âŒ ç”Ÿæˆ TensorRT engine å¤±è´¥ï¼")
        return

    # ä¿å­˜ Engine
    if fp16:
        engine_path = onnx_path.replace(".onnx", "fp16.engine")
    else:
        engine_path = onnx_path.replace(".onnx", "fp32.engine")
    with open(engine_path, "wb") as f:
        if trt_version8_bool:
            f.write(engine.serialize())
        else:
            f.write(engine)

    print(f"âœ… æˆåŠŸç”Ÿæˆ TensorRT engine: {engine_path} ğŸš€")


# è¿è¡Œè½¬æ¢
onnx_models = ["stereomodel\HITStereo\weights\model_float32_opt.onnx"]
# onnx_models = ["stereomodel\HITStereo\weights\model_float32_opt.onnx"]
# onnx_models = ["stereomodel/IGEV++RTStereo/weights/rt_sceneflow_640480.onnx"]
# onnx_models = ["stereomodel/AANet/weights/gmstereo-scale1-sceneflow-124a438f_1x3x480x640_sim.onnx"]
# onnx_models = ["stereomodel/FastAVCnet/weights/fast_acvnet_sceneflow_opset16_480x640.onnx"]
for model in onnx_models:
    if os.path.exists(model):
        convert_onnx_to_trt(model, fp16=True)
    else:
        print(f"âŒ ONNX æ¨¡å‹ {model} ä¸å­˜åœ¨ï¼Œè·³è¿‡è½¬æ¢ï¼")
