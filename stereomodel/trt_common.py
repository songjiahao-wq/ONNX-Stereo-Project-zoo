import os

os.environ['CUDA_MODULE_LOADING'] = 'LAZY'
import tensorrt as trt
from packaging import version
trt_version = trt.__version__
compare_version = version.parse("8.6.2")
# æ¯”è¾ƒç‰ˆæœ¬
if version.parse(trt_version) > compare_version:
    trt_version8_bool = False
    print(f"âœ… TensorRT ç‰ˆæœ¬ {trt_version} å¤§äºæˆ–ç­‰äº {compare_version}")
else:
    trt_version8_bool = True
    print(f"âŒ TensorRT ç‰ˆæœ¬ {trt_version} å°äº {compare_version}")
trt.init_libnvinfer_plugins(None, "")

import pycuda.autoinit
import pycuda.driver as cuda
from typing import List, Optional, Tuple, Union
import warnings
import matplotlib.pyplot as plt
import numpy as np
import time
import cv2

height, width = 480, 640


class BaseTRTInference:
    """æ·±åº¦ä¼°è®¡æ¨¡å‹ç±»"""

    def __init__(self, engine_file):
        # åˆå§‹åŒ–TensorRTå¼•æ“
        self.cuda_ctx = pycuda.autoinit.context
        self.cuda = cuda
        TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
        with open(engine_file, "rb") as f:
            runtime = trt.Runtime(TRT_LOGGER)
            self.engine = runtime.deserialize_cuda_engine(f.read())
        # åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
        self.context = self.engine.create_execution_context()

        # âš ï¸ **åŠ¨æ€ batch å¤„ç†ï¼šæ˜¾å¼è®¾ç½® batch_size**
        # self.batch_size = 1  # å¯ä»¥æ”¹æˆä»»æ„æœ‰æ•ˆ batch_size
        # if trt_version8_bool:
        #     self.context.set_binding_shape(0, (self.batch_size, 3, height, width))
        #     self.context.set_binding_shape(1, (self.batch_size, 3, height, width))
        # else:
        #     self.context.set_input_shape("input_name_0", (self.batch_size, 3, height, width))
        #     self.context.set_input_shape("input_name_1", (self.batch_size, 3, height, width))

        # ç»‘å®šè¾“å…¥è¾“å‡º
        self.inputs = []
        self.outputs = []
        self.bindings = []
        for binding_index in range(self.engine.num_io_tensors):
            binding_name = self.engine.get_tensor_name(binding_index)  # âš ï¸ ä¿®æ­£æ–¹æ³•
            dtype = self.engine.get_tensor_dtype(binding_name)  # âš ï¸ ä¿®æ­£æ–¹æ³•
            shape = self.context.get_tensor_shape(binding_name)  # âš ï¸ ç›´æ¥è·å–å®é™… shape
            size = trt.volume(shape) * np.dtype(np.float32).itemsize

            print(f"ğŸ”¹ {binding_name} Shape: {shape}")  # è°ƒè¯•è¾“å‡º
            shape[0] = 1
            host_mem = np.empty(shape, dtype=np.float32)
            device_mem = cuda.mem_alloc(host_mem.nbytes)
            if self.engine.get_tensor_mode(binding_name) == trt.TensorIOMode.INPUT:
                self.inputs.append({"host": host_mem, "device": device_mem})
            else:
                self.outputs.append({"host": host_mem, "device": device_mem})
            self.bindings.append(int(device_mem))
        self.height, self.width = height, width
    def __call__(self, left_img, right_img):
        return self.update(left_img, right_img)

    def preprocess_image(self, image):
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = cv2.resize(image, (width, height))
        image_input = np.transpose(image, (2, 0, 1))[None, :, :, :].astype(np.float32)
        return np.ascontiguousarray(image_input)

    def update(self, left_image, right_image):
        """
        è¿›è¡Œæ·±åº¦ä¼°è®¡æ¨ç†ï¼Œè¿”å›è§†å·®å›¾ï¼ˆæ·±åº¦å›¾ï¼‰ã€‚
        """
        self.cuda_ctx.push()

        self.img_height, self.img_width = left_image.shape[:2]
        # **1ï¸âƒ£ é¢„å¤„ç†**
        left_image_input = self.preprocess_image(left_image)
        right_image_input = self.preprocess_image(right_image)
        outputs = self.inference(left_image_input, right_image_input)
        # **6ï¸âƒ£ è§£æè¾“å‡º**
        self.disparity_map = self.process_output(outputs)
        self.cuda_ctx.pop()

        return self.disparity_map

    def process_output(self, outputs):
        
        disp_pred = outputs.reshape(1, 1, self.height, self.width)  # ç¡®ä¿ shape æ­£ç¡®
        disp_pred = np.squeeze(disp_pred[:, 0, :, :])  # ç§»é™¤ batch ç»´åº¦
        return disp_pred

    def inference(self, left_image_input, right_image_input):
        """
        è¿›è¡Œæ·±åº¦ä¼°è®¡æ¨ç†ï¼Œè¿”å›è§†å·®å›¾ï¼ˆæ·±åº¦å›¾ï¼‰ã€‚
        """
        # **2ï¸âƒ£ ä¼ è¾“æ•°æ®åˆ° GPU**
        cuda.memcpy_htod(self.inputs[0]["device"], left_image_input)
        cuda.memcpy_htod(self.inputs[1]["device"], right_image_input)
        # **3ï¸âƒ£ æ‰§è¡Œ TensorRT æ¨ç†**
        success = self.context.execute_v2(bindings=self.bindings)
        # **4ï¸âƒ£ ä» GPU æ‹·è´è¾“å‡º**
        
        for i in range(len(self.outputs)):
            cuda.memcpy_dtoh(self.outputs[i]["host"], self.outputs[i]["device"])

        # **5ï¸âƒ£ ç¡®ä¿è¾“å‡ºæœ‰æ•ˆ**
        if np.isnan(self.outputs[0]["host"]).sum() > 0:
            raise RuntimeError("[ERROR] æ¨ç†è¾“å‡ºåŒ…å« NaNï¼")
        # **6ï¸âƒ£ è§£æè¾“å‡º**
        outputs = self.outputs[-1]["host"]

        return outputs

    def draw_disparity(self):
        disparity_map = cv2.resize(self.disparity_map, (self.img_width, self.img_height))
        
        # print(np.max(disparity_map), np.min(disparity_map))
        
        norm_disparity_map = 255 * ((disparity_map - np.min(disparity_map)) /
                                    (np.max(disparity_map) - np.min(disparity_map)))

        return cv2.applyColorMap(cv2.convertScaleAbs(norm_disparity_map, 1), cv2.COLORMAP_JET)
    def measure_speed(self):
        cuda.Context.synchronize()
        start_time = time.time()
        input_left = np.ascontiguousarray(np.zeros((1, 3, self.height, self.width), dtype=np.float32))
        input_right = np.ascontiguousarray(np.zeros((1, 3, self.height, self.width), dtype=np.float32))
        for _ in range(1000):
            self.inference(input_left, input_right)
        cuda.Context.synchronize()
        end_time = time.time()
        
        print(f"ğŸ”¹ æ¨ç†è€—æ—¶: {(end_time - start_time)} ms)